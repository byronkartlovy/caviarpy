{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/SPY.xlsx')\n",
    "df.columns = df.iloc[5].values\n",
    "df = df.iloc[6:].iloc[::-1].reset_index(drop=True)\n",
    "df['Log Return'] = df.PX_LAST.apply(lambda x: np.log(x)).diff()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.array([1,2,3,4,5,6,7,8]) < np.ones(8) * 2) - 1) * ((np.array([1,2,3,4,5,6,7,8]) < np.ones(8) * 2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric(y, beta, q):\n",
    "    \"\"\"\n",
    "    f_t(beta) = b1 + b2 * f_t-1(beta) + b3 * |y_t-1|\n",
    "    \"\"\"\n",
    "    VaR = np.zeros_like(y)\n",
    "    VaR[0] = np.quantile(y[:300], q)\n",
    "    \n",
    "    b1, b2, b3 = beta\n",
    "    for i in range(1, len(y)):\n",
    "        VaR[i] = b1 + b2 * VaR[i-1] + b3 * abs(y[i-1])\n",
    "    \n",
    "    return VaR\n",
    "\n",
    "def loss(y, VaR, q):\n",
    "    dev = y - VaR\n",
    "    return np.mean(np.maximum(q * dev, (q - 1) * dev))\n",
    "\n",
    "def sigmoid(x, G):\n",
    "    \"\"\"\n",
    "    mimic indicator function I(x<=0)\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(G*x))\n",
    "\n",
    "def derivatives_fbeta(model):\n",
    "    \"\"\"\n",
    "    symmetric:\n",
    "    asymmetric:\n",
    "    adaptive:\n",
    "    igarch:\n",
    "    \"\"\"\n",
    "    if model == 'symmetric':\n",
    "        pass # -1, - f[t-1]\n",
    "    elif model == 'asymmetric':\n",
    "        pass\n",
    "    elif model == 'adaptive':\n",
    "        pass\n",
    "    elif model == 'igarch':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong Model!')\n",
    "\n",
    "def get_gradient(y, beta, VaR, q, G):\n",
    "    \"\"\"\n",
    "      d(RQ)/dbeta\n",
    "    = sum[ (q - sigmoid(y - f(beta))) * d(y - f(beta))/dbeta +\n",
    "           (y - f(beta)) * d(q - sigmoid(y - f(beta)))/dbeta ]\n",
    "    \"\"\"\n",
    "    gradient = np.zeros_like(beta)\n",
    "    \n",
    "    dev = y - VaR\n",
    "    sigmoid_dev = sigmoid(dev, G)\n",
    "    for t in range(1, len(y)):\n",
    "        gradient[0] += (\n",
    "            (q - sigmoid_dev[t]) * (- 1 - beta[1] * gradient[0]) +\n",
    "            dev[t] * ((sigmoid_dev[t] - sigmoid_dev[t] ** 2) * G * (- 1 - beta[1] * gradient[0]))\n",
    "        )\n",
    "        \n",
    "        gradient[1] += (\n",
    "            (q - sigmoid_dev[t]) * (- beta[1] * gradient[1] - VaR[t-1]) +\n",
    "            dev[t] * ((sigmoid_dev[t] - sigmoid_dev[t] ** 2) * G * (- VaR[t-1] - beta[1] * gradient[1]))\n",
    "        )\n",
    "        \n",
    "        gradient[2] += (\n",
    "            (q - sigmoid_dev[t]) * (- abs(y[t-1]) - beta[1] * gradient[2]) +\n",
    "            dev[t] * ((sigmoid_dev[t] - sigmoid_dev[t] ** 2) * G * (- abs(y[t-1]) - beta[1] * gradient[2]))\n",
    "        )\n",
    "    return gradient\n",
    "\n",
    "def gradient_descent(y, q=0.05, G=10, learning_rate=1e-10, max_iter=100, tol=1e-10):\n",
    "    y = np.array(y)\n",
    "    beta = np.random.uniform(-1, 1, 3)\n",
    "    VaR = symmetric(y, beta, q)\n",
    "    last = loss(y, VaR, q)\n",
    "    print(f'[0/{max_iter}] Loss: {last:.4f}')\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        gradient = get_gradient(y, beta, VaR, q, G)\n",
    "        beta -= learning_rate * gradient\n",
    "        VaR = symmetric(y, beta, q)\n",
    "        current = loss(y, VaR, q)\n",
    "        print(f'[{i+1}/{max_iter}] Loss: {current:.4f} Beta: {beta}')\n",
    "        if last - current < -np.inf: # tol:\n",
    "            print('Early stopped.')\n",
    "            print(f'Final Loss: {current:.4f} Beta: {beta}')\n",
    "            return beta + learning_rate * gradient\n",
    "        \n",
    "        last = current\n",
    "    \n",
    "    print(f'Finished {max_iter} loop')\n",
    "    print(f'Final Loss: {current:.4f}')\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = (df['Log Return'].dropna() - df['Log Return'].dropna().mean()).reset_index(drop=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = gradient_descent(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR = symmetric(returns, beta, q=0.05)\n",
    "plt.plot(returns)\n",
    "plt.plot(VaR)\n",
    "np.sum(returns < VaR) / len(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
