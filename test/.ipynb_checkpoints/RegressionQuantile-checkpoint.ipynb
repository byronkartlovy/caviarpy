{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import linprog\n",
    "from sklearn.linear_model import QuantileRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(100), np.random.normal(0, 5, size=(100, 5))]\n",
    "beta = np.array([10, 1, 2, 3, 4, 5])\n",
    "y = X @ beta + np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print (cp.installed_solvers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileRegression:\n",
    "    \"\"\"\n",
    "    Original form:\n",
    "        \n",
    "        min. Î£ max[(q-1) * (y - yhat)_i, q * (y - yhat)_i]\n",
    "    \n",
    "    where y_hat can be estimated by 4 CAViaR functions:\n",
    "    1. Adaptive:     f(B1)_t = f(B1)_t-1 + B1 * {[1 + exp(G * [y_t-1 - f(B1)_t-1])]^-1 - q}\n",
    "    2. Symmetric:    f(B)_t = B1 + B2 f(B)_t-1 + B3 |y_t-1|\n",
    "    3. Assymmetric:  f(B)_t = B1 + B2 f(B)_t-1 + B3 max(y_t-1, 0) + B4 min(y_t-1, 0)\n",
    "    4. IGRACH(1, 1): f(B)_t = (B1 + B2 f(B)_t-1**2 + B3 y_t-1**2)**0.5\n",
    "    \"\"\"\n",
    "    def __init__(self, theta, tol=1e-10):\n",
    "        self.theta = theta # theta-quantile\n",
    "        self.tol = tol # tolerance for loss to break the loop\n",
    "    \n",
    "    def fit(self, X, y, fit_intercept=False):\n",
    "        \"\"\"\n",
    "        if X == None => autoregressive; else normal regerssion\n",
    "        \"\"\"\n",
    "        # data preparation\n",
    "        self.n, self.p = X.shape\n",
    "        \n",
    "        # if data itself doesnt contain intercept term\n",
    "        if fit_intercept:\n",
    "            self.p += 1\n",
    "            X = np.c_[np.ones(self.n), X]\n",
    "            \n",
    "        # initialize the params to recursively fit the data\n",
    "        loss = np.inf\n",
    "        beta_hat = cp.Variable(self.p)\n",
    "        \n",
    "        loss_fct = cp.sum(cp.maximum(self.theta * (y - X @ beta_hat),\n",
    "                                     (self.theta - 1) * (y - X @ beta_hat)))\n",
    "        prob = cp.Problem(cp.Minimize(loss_fct))\n",
    "        prob.solve(solver='ECOS')\n",
    "        \n",
    "        self.params = beta_hat.value\n",
    "\n",
    "    def autoregressive_fit(self, returns):\n",
    "        self.n = returns.shape[0]\n",
    "        first = True\n",
    "        count = 0\n",
    "        \n",
    "        params = np.random.uniform(0, 1, 4)\n",
    "        sigmas = abs(np.random.normal(0, 1, self.n+1))\n",
    "        \n",
    "        constant_term = np.ones_like(returns)\n",
    "        while True:\n",
    "            if not first:\n",
    "                sigmas = self.asymmetric_slope(returns, self.params)\n",
    "            else:\n",
    "                first = False\n",
    "            X = np.c_[constant_term, sigmas[:-1], np.maximum(returns, 0), np.minimum(returns, 0)]\n",
    "            y = sigmas[1:]\n",
    "            self.fit(X, y)\n",
    "            print(self.params)\n",
    "            \n",
    "            if count == 20:\n",
    "                break\n",
    "            count += 1\n",
    "\n",
    "    def fit_LP(self, X, y, fit_intercept=True):\n",
    "        \"\"\"\n",
    "        Epigraph form (LP):\n",
    "\n",
    "            min. 1Tt\n",
    "            s.t. max[(q-1) * (y - yhat), q * (y - yhat)]_i <= ti\n",
    "        \n",
    "        let mxi == max[(q-1) * (y - yhat), q * (y - yhat)]_i\n",
    "        since mxi is always a positive value, it implies mxi <= ti only\n",
    "        \n",
    "        if y - y_hat positive => q; else q - 1\n",
    "        \"\"\"       \n",
    "        # data preparation\n",
    "        self.n, self.p = X.shape\n",
    "        \n",
    "        # if data itself doesnt contain intercept term\n",
    "        if fit_intercept:\n",
    "            self.p += 1\n",
    "            X = np.c_[np.ones(self.n), X]\n",
    "            \n",
    "        # initialize the params to recursively fit the data\n",
    "        self.params = np.random.uniform(0, 1, self.p)\n",
    "        \n",
    "        # fit the data\n",
    "        loss = np.inf\n",
    "        \n",
    "        for i in range(10000):\n",
    "            # calculate the deviations\n",
    "            y_hat = X @ self.params\n",
    "            dev = y - y_hat\n",
    "            \n",
    "            # the lower bounds of t\n",
    "            lowers = np.maximum((self.theta-1) * (dev), self.theta * (dev))\n",
    "            bounds = [(lb, None) for lb in lowers]\n",
    "            \n",
    "            # solve the above LP\n",
    "            res = linprog(np.ones_like(y), bounds=bounds)\n",
    "            if loss - res.fun <= self.tol:\n",
    "                break\n",
    "            loss = res.fun\n",
    "            \n",
    "            # update the betas\n",
    "            t = res.x\n",
    "            q_indicator = np.where(dev>0, self.theta, self.theta-1)\n",
    "            self.params = np.linalg.pinv(X) @ (y - t / q_indicator)\n",
    "        \n",
    "    def loss(self, y, y_hat):\n",
    "        # sum of absolute error\n",
    "        dev = y - y_hat\n",
    "        return np.sum(np.maximum(self.theta * dev, (self.theta - 1) * dev))\n",
    "\n",
    "    def asymmetric_slope(self, returns, params):\n",
    "        b1, b2, b3, b4 = params\n",
    "        sigmas = np.zeros(returns.shape[0]+1)\n",
    "        sigmas[0] = np.std(returns) # im not sure\n",
    "        for t in range(1, len(sigmas)):\n",
    "            sigmas[t] = b1 + b2 * sigmas[t-1] + max(b3 * returns[t-1], 0) + b4 * min(b3 * returns[t-1], 0)\n",
    "        return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(100), np.random.normal(0, 5, size=(100, 5))]\n",
    "beta = np.array([100, -1, 2, -3, 4, -5])\n",
    "y = X @ beta + np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr = QuantileRegression(0.01)\n",
    "qr_sklearn = QuantileRegressor(quantile=0.01, alpha=0, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantileRegression' object has no attribute 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_321609/3188993367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoregressive_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_321609/4202725793.py\u001b[0m in \u001b[0;36mautoregressive_fit\u001b[0;34m(self, returns)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msigmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mconstant_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantileRegression' object has no attribute 'n'"
     ]
    }
   ],
   "source": [
    "qr.autoregressive_fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr.fit(X, y, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_sklearn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98.31215737, -0.94949759,  1.9675716 , -2.94511591,  4.06207583,\n",
       "       -4.94583376])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98.31215737, -0.94949759,  1.9675716 , -2.94511591,  4.06207583,\n",
       "       -4.94583376])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
